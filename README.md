# VLAC (Vision Language Action Context)

## Abstract

---
VLAC is a currently under active development of an AI use VLA (Vision Language Action) model with context.
This model is based on multiple papers: [CoT-VLA](https://arxiv.org/pdf/2503.22020), [VILA-U](https://arxiv.org/pdf/2409.04429), [DeepSeek-r1](https://arxiv.org/pdf/2501.12948)
The goal of this model is being an autonomous AI-powered Non-Player Character (NPC) enhanced with deep learning capabilities
that can perceive, understand, and interact naturally within video game environments.
This intelligent agent leverages vision-language-action models to process visual input, understand context,
and generate appropriate responses and actions in real-time gameplay situations.
The system acts as a self-directed virtual entity capable of making independent decisions, adapting to dynamic gaming scenarios,
and engaging in meaningful interactions with human players.

## Affiliation

---
This project is being conducted as part of a final-year internship for the Master's Degree in Computer Science, Video Game specialization,
at the Jean Perrin Faculty of Sciences in Lens, France. The internship takes place at the LML (Laboratory of Mathematics of Lens)
from April 25th, 2025 to July 25th, 2025.